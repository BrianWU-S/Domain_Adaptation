{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Domain Adaptation\n",
    "### **What is domain adaptation:**\n",
    "\n",
    "Domain adaptation is a field associated with machine learning and transfer learning. This scenario arises when we aim at learning from a source data distribution a well performing model on a different (but related) target data distribution. In this assgiment we focus on single-source domain adaptation. Note that, when more than one source distribution is available the problem is referred to as multi-source domain adaptation.\n",
    "\n",
    "###  **Relationships with transfer learning:**\n",
    "\n",
    "Domain adaptation is a subcategory of transfer learning. In domain adaptation, the source and target domains all have the same feature space (but different distributions); in contrast, transfer learning includes cases where the target domain's feature space is different from the source feature space or spaces.\n",
    "\n",
    "###  **Why we need domain adaptation:**\n",
    "\n",
    "An important premise of traditional machine learning algorithms is that training data and test data must be independent and identically distributed. However, if the inputs at test time differ significantly from the training data, the traditional machine learning model might not perform very well. In these cases, domain adaptation comes to our rescue.\n",
    "\n",
    "###  **Classification:**\n",
    "* **Unsupervised domain adaptation**: the learning sample contains a set of labeled source domain examples with only unlabeled data in the target domain.\n",
    "* **Semi-supervised domain adaptation**: in this situation, we consider a \"small\" set of labeled target examples.\n",
    "* **Supervised domain adaptation**: all the examples considered are supposed to be labeled.\n",
    "\n",
    "###  **Different types of adaptation algorithms:**\n",
    "- **Reweighting algorithm**: \n",
    "    The objective is to reweight the source labeled sample such that it \"looks like\" the target sample (in terms of the error measure considered).\n",
    "- **Iterative algorithms**:\n",
    "    A method for adapting consists in iteratively \"auto-labeling\" the target examples. The principle is simple:\n",
    "    - a model h is learned from the labeled examples;\n",
    "    - h automatically labels some target examples;\n",
    "    - a new model is learned from the new labeled examples.\n",
    "- **Common representation space algorithms**:\n",
    "    The goal is to find or construct a common representation space for the two domains. The objective is to obtain a space in which the domains are close to each other while keeping good performances on the source labeling task. This can be achieved through the use of Adversarial machine learning techniques where feature representations from samples in different domains are encouraged to be indistinguishable.A well known model of this type is DANN, which is selected as the Deep Domain Adaptation Method for this assignment.\n",
    "- **Hierarchical Bayesian Model**:\n",
    "    The goal is to construct a Bayesian hierarchical model p(n), which is essentially a factorization model for counts n, to derive domain-dependent latent representations allowing both domain-specific and globally shared latent factors.\n",
    "\n",
    "### **Different types of domain adaptation methods:**\n",
    "- **Distribution Adaptation** (Minimize the probability distribution distance so that the probability distribution of the source domain and the target domain are similar)\n",
    "    - Marginal Distribution Adaptation\n",
    "        - TCA (Transfer Component Analysis)\n",
    "        - MMD (Maximum Mean Discrepancy)\n",
    "        - DDC (Deep Domain Confusion): MMD + Neural Network\n",
    "        - DAN (Deep Adaptation Networks): MKK-MMD + Neural Network\n",
    "        - DME (Distribution-Matching Embedding): matrix transformation + projection\n",
    "        - CMD (Central Moment Discrepancy): K-order MMD\n",
    "    - Conditional Distribution Adaptation\n",
    "        - CTC (Conditional Transferrable Components)\n",
    "    - Joint Distribution Adaptation\n",
    "        - JDA (Joint Distribution Adaptation): TCA + Conditional distribution adaptation\n",
    "        - ARTL (Adaptation Regularization): JDA + Classifier learning\n",
    "        - VDA (Visual Domain Adaptation): JDA+ Inner class distance + Among class distance\n",
    "        - JGSA (Joint Geometrical and Statistical Alignment): JDA + Inner class distance + Among class distance + Label adaptation\n",
    "        - JAN (Joint Adaptation Networks): JDA + JMMD, used in deep network\n",
    "        - BDA (Balanced Distribution Adaptation): Add the balance factor to dynamically measure the importance of the two distributions\n",
    "- **Feature Selection** (Select and extract shared features from the source domain and target domain, and establish a unified model)\n",
    "    - SCL (Structural Correspondence Learning)\n",
    "    - TJM (Transfer Joint Matching): MMD Distribution Adapation + Source Domain Sampling\n",
    "    - FSSL (Feature Selection and Structure Preservation): Feature Selection + Information Immutability\n",
    "- **Subspace Learning** (Transform the source domain and target domain to the same subspace, and then build a unified model)\n",
    "    - Statistical Characteristics Alignment\n",
    "        - SA (Subspace Alignment): Directly seek a linear transformation, which transform the source into the target space\n",
    "        - SDA (Subspace Distribution Alignment): SA + Prob Distribution Adaptation\n",
    "        - CORAL (CORrelation Alignment): Minimize the second-order statistical characteristics of the source and target domains\n",
    "        - Deep-CORAL: CORAL + DNN\n",
    "    - Manifold Learning\n",
    "        - SGF (Sample Geodesic Flow)\n",
    "        - GFK (Geodesic Flow Kernel): SGF + Gaussian Kernel\n",
    "        - DIP (Domain-Invariant Projection):\n",
    "- **Deep Learning**\n",
    "    - Domain-Adversarial Neural Network (DANN): ICCV 2014\n",
    "    - Deep Adaptation Networks (DAN): ICML 2015\n",
    "    - Simultaneous feature and task transfer: ICCV 2015 \n",
    "    - Joint Adaptation Networks (JAN): ICML 2017\n",
    "    - Deep Hashing Network (DHN): CVPR 2017\n",
    "    - Adversarial Discriminative Domain Adaptation (ADDA): arXiv 2017\n",
    "    - Learning to Transfer (L2T): arXiv 2017\n",
    "    - Label Efficient Learning of Transferable Representations across Domains and Tasks: NIPS 2017\n",
    "\n",
    "Note:\n",
    "\n",
    "1. General result of domain adaptation methods: \n",
    "    Deep Learning methods(DDC,DAN,JAN,...) > Balanced Distribution Adaptation methods(BDA,..) > Joint Distribution Adaptation methods(JDA,..) > Edge distribution adaptation methods(TCA,...) > Conditional distribution adaptation methods(CTC,...)\n",
    "2. Subspace Learning's advantage: simple method + efficient calculation\n",
    "\n",
    "Useful links:\n",
    "- [Domain adaptation theoretical analysis:](https://zhuanlan.zhihu.com/p/50710267)\n",
    "\n",
    "- [Domain adaptation overview:](http://jd92.wang/assets/files/l12_da.pdf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Methods we used:\n",
    "- Traditional methods:\n",
    "    - TCA\n",
    "    - JDA\n",
    "    - BDA,WBDA\n",
    "    - CORAL\n",
    "- Deep methods:\n",
    "    - DANN (SVM classifier, Label predictor)\n",
    "    - DDC DeepCORAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset description:\n",
    "Office-Home dataset is a domain adaptation dataset, which consists of 65 categories of office depot from four domains (i.e., A: Art, C:Clipart, P:Product, R: Real-world).\n",
    "\n",
    "The **raw images** can be downloaded from: http://hemanthdv.org/OfficeHome-Dataset/.\n",
    "\n",
    "The 2048-dim ResNet50 **deep learning features** of all images can be downloaded from:https://pan.baidu.com/s/1qvcWJCXVG8JkZnoM4BVoGg#list/path=%2F.\n",
    "\n",
    "### Note:\n",
    "The following experiments will conduct in the following three settings (source domain -> target domain):\n",
    "- a) A->R;\n",
    "- b) C->R; \n",
    "- c) P->R\n",
    "\n",
    "In X->Y setting, use the deep learning features X_X.csv as source domain features and X_Y.csv as target domain features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "import scipy.linalg\n",
    "import sklearn.metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sd_features_AA=pd.read_csv(r'Dataset\\Office-Home_resnet50\\Art_Art.csv',header=None)\n",
    "sd_features_CC=pd.read_csv(r'Dataset\\Office-Home_resnet50\\Clipart_Clipart.csv',header=None)\n",
    "sd_features_PP=pd.read_csv(r'Dataset\\Office-Home_resnet50\\Product_Product.csv',header=None)\n",
    "td_features_AR=pd.read_csv(r'Dataset\\Office-Home_resnet50\\Art_RealWorld.csv',header=None)\n",
    "td_features_CR=pd.read_csv(r'Dataset\\Office-Home_resnet50\\Clipart_RealWorld.csv',header=None)\n",
    "td_features_PR=pd.read_csv(r'Dataset\\Office-Home_resnet50\\Product_RealWorld.csv',header=None)\n",
    "\n",
    "sd_labels_AA=sd_features_AA.iloc[:,-1].astype(int)\n",
    "sd_labels_CC=sd_features_CC.iloc[:,-1].astype(int)\n",
    "sd_labels_PP=sd_features_PP.iloc[:,-1].astype(int)\n",
    "td_labels_AR=td_features_AR.iloc[:,-1].astype(int)\n",
    "td_labels_CR=td_features_CR.iloc[:,-1].astype(int)\n",
    "td_labels_PR=td_features_PR.iloc[:,-1].astype(int)\n",
    "\n",
    "sd_features_AA.drop(labels=2048,axis=1,inplace=True)\n",
    "sd_features_CC.drop(labels=2048,axis=1,inplace=True)\n",
    "sd_features_PP.drop(labels=2048,axis=1,inplace=True)\n",
    "td_features_AR.drop(labels=2048,axis=1,inplace=True)\n",
    "td_features_CR.drop(labels=2048,axis=1,inplace=True)\n",
    "td_features_PR.drop(labels=2048,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2427 entries, 0 to 2426\n",
      "Columns: 2048 entries, 0 to 2047\n",
      "dtypes: float64(2048)\n",
      "memory usage: 37.9 MB\n"
     ]
    }
   ],
   "source": [
    "sd_features_AA.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2038</th>\n",
       "      <th>2039</th>\n",
       "      <th>2040</th>\n",
       "      <th>2041</th>\n",
       "      <th>2042</th>\n",
       "      <th>2043</th>\n",
       "      <th>2044</th>\n",
       "      <th>2045</th>\n",
       "      <th>2046</th>\n",
       "      <th>2047</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.339104</td>\n",
       "      <td>0.094242</td>\n",
       "      <td>0.574024</td>\n",
       "      <td>1.576792</td>\n",
       "      <td>0.208177</td>\n",
       "      <td>0.048539</td>\n",
       "      <td>0.514466</td>\n",
       "      <td>0.761950</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>...</td>\n",
       "      <td>0.140119</td>\n",
       "      <td>0.194172</td>\n",
       "      <td>0.217043</td>\n",
       "      <td>0.408074</td>\n",
       "      <td>0.361293</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.600183</td>\n",
       "      <td>0.209631</td>\n",
       "      <td>0.133738</td>\n",
       "      <td>0.046542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003123</td>\n",
       "      <td>0.017756</td>\n",
       "      <td>0.007342</td>\n",
       "      <td>0.320789</td>\n",
       "      <td>0.033795</td>\n",
       "      <td>0.040097</td>\n",
       "      <td>0.607107</td>\n",
       "      <td>0.069854</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.008634</td>\n",
       "      <td>...</td>\n",
       "      <td>0.190653</td>\n",
       "      <td>0.019870</td>\n",
       "      <td>0.103396</td>\n",
       "      <td>0.054031</td>\n",
       "      <td>0.133227</td>\n",
       "      <td>0.038206</td>\n",
       "      <td>0.073742</td>\n",
       "      <td>0.128579</td>\n",
       "      <td>0.028439</td>\n",
       "      <td>0.083659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.756924</td>\n",
       "      <td>0.138735</td>\n",
       "      <td>0.828411</td>\n",
       "      <td>0.850277</td>\n",
       "      <td>0.064541</td>\n",
       "      <td>0.121117</td>\n",
       "      <td>0.417071</td>\n",
       "      <td>0.957303</td>\n",
       "      <td>1.156487</td>\n",
       "      <td>0.437190</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271353</td>\n",
       "      <td>0.537854</td>\n",
       "      <td>0.425364</td>\n",
       "      <td>1.189281</td>\n",
       "      <td>0.463679</td>\n",
       "      <td>0.078043</td>\n",
       "      <td>0.372926</td>\n",
       "      <td>0.287346</td>\n",
       "      <td>0.244757</td>\n",
       "      <td>0.237532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.447522</td>\n",
       "      <td>0.960308</td>\n",
       "      <td>1.076476</td>\n",
       "      <td>0.378051</td>\n",
       "      <td>0.447546</td>\n",
       "      <td>0.356158</td>\n",
       "      <td>0.268489</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.085499</td>\n",
       "      <td>0.351589</td>\n",
       "      <td>...</td>\n",
       "      <td>0.227814</td>\n",
       "      <td>0.154202</td>\n",
       "      <td>0.102128</td>\n",
       "      <td>0.328863</td>\n",
       "      <td>0.303151</td>\n",
       "      <td>0.226952</td>\n",
       "      <td>0.408608</td>\n",
       "      <td>0.770035</td>\n",
       "      <td>2.369065</td>\n",
       "      <td>0.162354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.097336</td>\n",
       "      <td>0.172056</td>\n",
       "      <td>0.242983</td>\n",
       "      <td>0.123272</td>\n",
       "      <td>0.285455</td>\n",
       "      <td>0.198112</td>\n",
       "      <td>0.376254</td>\n",
       "      <td>0.547338</td>\n",
       "      <td>0.221591</td>\n",
       "      <td>0.020542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.658062</td>\n",
       "      <td>0.166302</td>\n",
       "      <td>0.695773</td>\n",
       "      <td>0.300673</td>\n",
       "      <td>0.229382</td>\n",
       "      <td>0.036234</td>\n",
       "      <td>0.178590</td>\n",
       "      <td>0.523891</td>\n",
       "      <td>0.171992</td>\n",
       "      <td>0.024020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2048 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.339104  0.094242  0.574024  1.576792  0.208177  0.048539  0.514466   \n",
       "1  0.003123  0.017756  0.007342  0.320789  0.033795  0.040097  0.607107   \n",
       "2  1.756924  0.138735  0.828411  0.850277  0.064541  0.121117  0.417071   \n",
       "3  0.447522  0.960308  1.076476  0.378051  0.447546  0.356158  0.268489   \n",
       "4  0.097336  0.172056  0.242983  0.123272  0.285455  0.198112  0.376254   \n",
       "\n",
       "       7         8         9     ...      2038      2039      2040      2041  \\\n",
       "0  0.761950  0.003735  0.677419  ...  0.140119  0.194172  0.217043  0.408074   \n",
       "1  0.069854  0.005501  0.008634  ...  0.190653  0.019870  0.103396  0.054031   \n",
       "2  0.957303  1.156487  0.437190  ...  0.271353  0.537854  0.425364  1.189281   \n",
       "3  0.000000  1.085499  0.351589  ...  0.227814  0.154202  0.102128  0.328863   \n",
       "4  0.547338  0.221591  0.020542  ...  0.658062  0.166302  0.695773  0.300673   \n",
       "\n",
       "       2042      2043      2044      2045      2046      2047  \n",
       "0  0.361293  0.070492  0.600183  0.209631  0.133738  0.046542  \n",
       "1  0.133227  0.038206  0.073742  0.128579  0.028439  0.083659  \n",
       "2  0.463679  0.078043  0.372926  0.287346  0.244757  0.237532  \n",
       "3  0.303151  0.226952  0.408608  0.770035  2.369065  0.162354  \n",
       "4  0.229382  0.036234  0.178590  0.523891  0.171992  0.024020  \n",
       "\n",
       "[5 rows x 2048 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_features_AA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        3\n",
       "1       15\n",
       "2       53\n",
       "3       21\n",
       "4        0\n",
       "        ..\n",
       "2422    19\n",
       "2423     4\n",
       "2424    35\n",
       "2425     4\n",
       "2426     0\n",
       "Name: 2048, Length: 2427, dtype: int32"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_labels_AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# convert to numpy\n",
    "sd_features_AA=sd_features_AA.to_numpy()\n",
    "sd_features_CC=sd_features_CC.to_numpy()\n",
    "sd_features_PP=sd_features_PP.to_numpy()\n",
    "td_features_AR=td_features_AR.to_numpy()\n",
    "td_features_CR=td_features_CR.to_numpy()\n",
    "td_features_PR=td_features_PR.to_numpy()\n",
    "sd_labels_AA=sd_labels_AA.to_numpy()\n",
    "sd_labels_CC=sd_labels_CC.to_numpy()\n",
    "sd_labels_PP=sd_labels_PP.to_numpy()\n",
    "td_labels_AR=td_labels_AR.to_numpy()\n",
    "td_labels_CR=td_labels_CR.to_numpy()\n",
    "td_labels_PR=td_labels_PR.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3, 15, 53, ..., 35,  4,  0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_labels_AA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
       "       51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(sd_labels_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2427, 2048)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd_features_AA.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN without Domain Adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def knn_model(Xs,Ys,Xt,Yt,n_neighbors=1):\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(Xs, Ys.ravel())\n",
    "    y_pred = knn.predict(Xt)\n",
    "    y_train_pred=knn.predict(Xs)\n",
    "    acc = sklearn.metrics.accuracy_score(Yt, y_pred)\n",
    "    acc_train=sklearn.metrics.accuracy_score(Ys, y_train_pred)\n",
    "    return acc,acc_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def kernel(ker, X1, X2, gamma):\n",
    "    K = None\n",
    "    if not ker or ker == 'primal':\n",
    "        K = X1\n",
    "    elif ker == 'linear':\n",
    "        if X2 is not None:\n",
    "            K = sklearn.metrics.pairwise.linear_kernel(np.asarray(X1).T, np.asarray(X2).T)\n",
    "        else:\n",
    "            K = sklearn.metrics.pairwise.linear_kernel(np.asarray(X1).T)\n",
    "    elif ker == 'rbf':\n",
    "        if X2 is not None:\n",
    "            K = sklearn.metrics.pairwise.rbf_kernel(np.asarray(X1).T, np.asarray(X2).T, gamma)\n",
    "        else:\n",
    "            K = sklearn.metrics.pairwise.rbf_kernel(np.asarray(X1).T, None, gamma)\n",
    "    return K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "acc_AR_test,acc_AR_train=knn_model(sd_features_AA,sd_labels_AA,td_features_AR,td_labels_AR)\n",
    "acc_CR_test,acc_CR_train=knn_model(sd_features_CC,sd_labels_CC,td_features_CR,td_labels_CR)\n",
    "acc_PR_test,acc_PR_train=knn_model(sd_features_PP,sd_labels_PP,td_features_PR,td_labels_PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A--> R:source domain acc 0.9983518747424804 target domain acc 0.6580215744778517\n",
      "C--> R:source domain acc 0.995418098510882 target domain acc 0.5873307321551526\n",
      "P--> R:source domain acc 0.9997747240369452 target domain acc 0.6956621528574707\n"
     ]
    }
   ],
   "source": [
    "print(\"A--> R:source domain acc\",acc_AR_train,'target domain acc',acc_AR_test)\n",
    "print(\"C--> R:source domain acc\",acc_CR_train,'target domain acc',acc_CR_test)\n",
    "print(\"P--> R:source domain acc\",acc_PR_train,'target domain acc',acc_PR_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 1. TCA （Transfer Component Analysis）\n",
    "**Main idea:**\n",
    "    将两个领域的数据一起映射到一个高维的再生核希尔伯特空间。在此空间中，最小化源和目标的数据距离，同时最大程度地保留它们各自的内部属性。此处距离为MMD(Maximum Mean Discrepancy)，最大均值差异（$dist(X^{'}_{src},X^{'}_{tar})=||1/n_1 \\sum_{i=1}^{n_1}\\phi (x_{scr_i})-1/n_2 \\sum_{j=1}^{n_2}\\phi (x_{tar_i})||_{H}$）。\n",
    "    \n",
    "那么，如何求出这个映射（原始空间--> 高维的再生核希尔伯特空间）呢？通常，一个难求出的映射可以用核函数的方法来求解：\n",
    "    MMD= trace(KL)-$\\lambda$trace(K)，其中K为kernel function (可以为线性核，高斯核，rbf核...)。因此，根据优化问题求解（求解拉格朗日对偶，详细见link）可得source domain data和target domain data经过映射、降维后为：$(KLK+\\lambda I)^{-1}KHK$ 的前m个特征值，其中K为kernel function， H 为中心矩阵（$H=I_{n_1+n_2}-1/(n_1+n_2)*\\ 11^T$），$L=\\begin{cases}\n",
    "    1/n_1^2 & x_i,x_j \\in X_{src}\\\\\n",
    "    1/n_2^2 & x_i,x_j \\in X_{tar}\\\\\n",
    "    -1/(n_1 n_2) & otherwise\\\\\n",
    "    \\end{cases}$\n",
    "\n",
    "**Pros and Cons:**\n",
    "Pros:\n",
    "实现简单，方法本身没有太多的限制，就跟PCA一样很好用\n",
    "Cons:\n",
    "对于大矩阵的运算计算开销很大 (主要开销在特征值计算上)\n",
    "\n",
    "Useful Link: https://zhuanlan.zhihu.com/p/26764147"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class TCA:\n",
    "    def __init__(self, kernel_type='primal', dim=30, lamb=1, gamma=1):\n",
    "        '''\n",
    "        Init func\n",
    "        :param kernel_type: kernel, values: 'primal' | 'linear' | 'rbf'\n",
    "        :param dim: dimension after transfer\n",
    "        :param lamb: lambda value in equation\n",
    "        :param gamma: kernel bandwidth for rbf kernel\n",
    "        '''\n",
    "        self.kernel_type = kernel_type\n",
    "        self.lamb = lamb\n",
    "        self.gamma = gamma\n",
    "        self.dim=dim\n",
    "\n",
    "    def fit(self, Xs, Xt):\n",
    "        '''\n",
    "        Transform Xs and Xt\n",
    "        :param Xs: ns * n_feature, source feature\n",
    "        :param Xt: nt * n_feature, target feature\n",
    "        :return: Xs_new and Xt_new after TCA\n",
    "        '''\n",
    "        X = np.hstack((Xs.T, Xt.T))\n",
    "        X /= np.linalg.norm(X, axis=0)\n",
    "        m, n = X.shape\n",
    "        ns, nt = len(Xs), len(Xt)\n",
    "        e = np.vstack((1 / ns * np.ones((ns, 1)), -1 / nt * np.ones((nt, 1))))\n",
    "        L = e * e.T\n",
    "        L = L / np.linalg.norm(L, 'fro')\n",
    "        H = np.eye(n) - 1 / n * np.ones((n, n))\n",
    "        K = kernel(self.kernel_type, X, None, gamma=self.gamma)\n",
    "        n_eye = m if self.kernel_type == 'primal' else n\n",
    "        a, b = np.linalg.multi_dot([K, L, K.T]) + self.lamb * np.eye(n_eye), np.linalg.multi_dot([K, H, K.T])\n",
    "        w, V = scipy.linalg.eig(a, b)\n",
    "        ind = np.argsort(w)\n",
    "        A = V[:, ind[:self.dim]]\n",
    "        Z = np.dot(A.T, K)\n",
    "        Z /= np.linalg.norm(Z, axis=0)\n",
    "        Xs_new, Xt_new = Z[:, :ns].T, Z[:, ns:].T\n",
    "        return Xs_new, Xt_new\n",
    "\n",
    "    def fit_predict(self, Xs, Ys, Xt, Yt,n_neighbors=5):\n",
    "        '''\n",
    "        Transform Xs and Xt, then make predictions on target using 1NN\n",
    "        :param Xs: ns * n_feature, source feature\n",
    "        :param Ys: ns * 1, source label\n",
    "        :param Xt: nt * n_feature, target feature\n",
    "        :param Yt: nt * 1, target label\n",
    "        :return: Accuracy and predicted_labels on the target domain\n",
    "        '''\n",
    "        Xs_new, Xt_new = self.fit(Xs, Xt)\n",
    "        clf = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "        clf.fit(Xs_new, Ys.ravel())\n",
    "        y_pred = clf.predict(Xt_new)\n",
    "        acc = sklearn.metrics.accuracy_score(Yt, y_pred)\n",
    "        return acc, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A--> R: The accuracy of TCA is: 0.6224\n"
     ]
    }
   ],
   "source": [
    "tca_AR = TCA(kernel_type='linear', dim=30, lamb=1, gamma=1)\n",
    "acc_AR, ypre_AR = tca_AR.fit_predict(sd_features_AA,sd_labels_AA,td_features_AR,td_labels_AR)\n",
    "print(f'A--> R: The accuracy of TCA is: {acc_AR:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C--> R: The accuracy of TCA is: 0.5699\n"
     ]
    }
   ],
   "source": [
    "tca_CR = TCA(kernel_type='linear', dim=30, lamb=1, gamma=1)\n",
    "acc_CR, ypre_CR = tca_CR.fit_predict(sd_features_CC,sd_labels_CC,td_features_CR,td_labels_CR)\n",
    "print(f'C--> R: The accuracy of TCA is: {acc_CR:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P--> R: The accuracy of TCA is: 0.6787\n"
     ]
    }
   ],
   "source": [
    "tca_PR = TCA(kernel_type='linear', dim=30, lamb=1, gamma=1)\n",
    "acc_PR, ypre_PR = tca_PR.fit_predict(sd_features_PP,sd_labels_PP,td_features_PR,td_labels_PR)\n",
    "print(f'P--> R: The accuracy of TCA is: {acc_PR:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "\n",
    "From the result we can see that all the TCA results is worse than the original KNN results. It means that this domain adaptation method cause `negative transfer`. Negative transfer means that the knowledge learned in the source domain has a negative effect on the learning in the target domain. \n",
    "\n",
    "The cause of negative transfer can be:\n",
    "- There is no/weak relation between source domain and target domain.(the problem of dataset)\n",
    "- The transfer learning method is not suitable for current dataset. (the problem of method)\n",
    "\n",
    "Here we consider the second cause as the one to result in bad performance. Selecting appropriate method can solve this cause. And there are new proposed ways to solve cause 1. One of the most famous anti-negative transfer learning methods is the `Transitive transfer learning`. When the two domains are not similar, we can use several intermediate domains between these two domains to complete the transfer of knowledge. Another significant work is `Distant domain transfer learning`, proposed by Prof. QiangYang.\n",
    "![image.jpg](images/1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 2. JDA (Joint Distribution Adaptation)\n",
    "**Difference between JDA and TCA:**\n",
    "\n",
    "1. JDA= TCA + Conditional distribution adaptation\n",
    "2. TCA是无监督的方法（边缘分布适配不需要label），JDA是监督的方法，需要源域有label；\n",
    "3. TCA不需要迭代，JDA需要迭代\n",
    "\n",
    "**Main idea:**\n",
    "JDA对数据的假设：1）源域和目标域边缘分布不同（这是肯定的，引入迁移学习的初衷）；2）源域和目标域条件分布不同（此在TCA中没有假设）。因此JDA方法所做的事就是同时适配源域和目标域的边缘分布和条件分布（此也称之为“联合分布”，但此时联合指的是同时适配，并非概率上的联合）。\n",
    "\n",
    "对于适配源域和目标域边缘分布，JDA使用TCA，寻找一个变换A （TCA中为映射$\\phi(.)$）,使得$P(A^T x_s),P(A^T x_t)$之间距离（MMD）尽可能的相近。同样，我们引入核方法，得到$D(D_s,D_t)=tr(A^T X M_0 X^T A)$，其中A对应K，$M_0$对应L。\n",
    "\n",
    "对于适配源域和目标域条件分布，JDA 寻找一个变换A，使得$P(y_s|A^T x_s),P(y_t|A^T x_t)$之间距离（MMD）尽可能的相近。然而此setting下并不知道$y_t$，因此使用贝叶斯方法+充分统计量，我们得到：$P(y_t|x_t)=p(y_t)p(x_t|y_t)$ (经充分统计量可以忽略$P(x_t)$)。而求$P(y_t)$，JDA使用在source domain上训练的弱分类器（e.g.KNN,LR）来预测伪标签，使用伪标签代替真实标签。得到了$P(y_s|A^T x_s),P(y_t|A^T x_t)$之后，同样用TCA方法可以适配。这里使用弱分类器预测的伪标签虽然不准确，但是可以通过迭代解决，每一次迭代的标签都是上一轮的伪标签，因此可以逐步增高预测的准确率。\n",
    "\n",
    "得到两个优化目标后，JDA将其结合起来得到优化目标：$\\min \\sum_{c=0}^C tr(A^T X M_c X^T A)+\\lambda ||A||_F^2$，其中第二项为正则项。添加constraint: $\\max A^T X H X^T A$，此限制确保了变换前后数据的方差不变（PCA思想）。合并上述三个目标得到JDA优化总目标：$\\min \\frac{\\sum_{c=0}^C tr(A^T X M_c X^T A)+\\lambda ||A||_F^2}{A^T X H X^T A}$。而此目标可以通过rayleigh quotient + 拉格朗日乘子法解决，得到:$(X\\sum_{c=0}^C M_c X^T+\\lambda I)A=XHX^TA\\phi$，其中$\\phi$为拉格朗日乘子。此时可通过Matlab直接求解。得到变换A。\n",
    "\n",
    "Useful Link: https://zhuanlan.zhihu.com/p/27336930"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class JDA:\n",
    "    def __init__(self, kernel_type='primal', dim=30, lamb=1, gamma=1, T=10):\n",
    "        '''\n",
    "        Init func\n",
    "        :param kernel_type: kernel, values: 'primal' | 'linear' | 'rbf'\n",
    "        :param dim: dimension after transfer\n",
    "        :param lamb: lambda value in equation\n",
    "        :param gamma: kernel bandwidth for rbf kernel\n",
    "        :param T: iteration number\n",
    "        '''\n",
    "        self.kernel_type = kernel_type\n",
    "        self.dim = dim\n",
    "        self.lamb = lamb\n",
    "        self.gamma = gamma\n",
    "        self.T = T\n",
    "\n",
    "    def fit_predict(self, Xs, Ys, Xt, Yt):\n",
    "        '''\n",
    "        Transform and Predict using 1NN as JDA paper did\n",
    "        :param Xs: ns * n_feature, source feature\n",
    "        :param Ys: ns * 1, source label\n",
    "        :param Xt: nt * n_feature, target feature\n",
    "        :param Yt: nt * 1, target label\n",
    "        :return: acc, y_pred, list_acc\n",
    "        '''\n",
    "        list_acc = []\n",
    "        X = np.hstack((Xs.T, Xt.T))\n",
    "        X /= np.linalg.norm(X, axis=0)\n",
    "        m, n = X.shape\n",
    "        ns, nt = len(Xs), len(Xt)\n",
    "        e = np.vstack((1 / ns * np.ones((ns, 1)), -1 / nt * np.ones((nt, 1))))\n",
    "        C = len(np.unique(Ys))\n",
    "        H = np.eye(n) - 1 / n * np.ones((n, n))\n",
    "\n",
    "        M = 0\n",
    "        Y_tar_pseudo = None\n",
    "        for t in range(self.T):\n",
    "            N = 0\n",
    "            M0 = e * e.T * C\n",
    "            if Y_tar_pseudo is not None and len(Y_tar_pseudo) == nt:\n",
    "                for c in range(0, C):\n",
    "                    e = np.zeros((n, 1))\n",
    "                    tt = Ys == c\n",
    "                    e[np.where(tt == True)] = 1 / len(Ys[np.where(Ys == c)])\n",
    "                    yy = Y_tar_pseudo == c\n",
    "                    ind = np.where(yy == True)\n",
    "                    inds = [item + ns for item in ind]\n",
    "                    e[tuple(inds)] = -1 / len(Y_tar_pseudo[np.where(Y_tar_pseudo == c)])\n",
    "                    e[np.isinf(e)] = 0\n",
    "                    N = N + np.dot(e, e.T)\n",
    "            M = M0 + N\n",
    "            M = M / np.linalg.norm(M, 'fro')\n",
    "            K = kernel(self.kernel_type, X, None, gamma=self.gamma)\n",
    "            n_eye = m if self.kernel_type == 'primal' else n\n",
    "            a, b = np.linalg.multi_dot([K, M, K.T]) + self.lamb * np.eye(n_eye), np.linalg.multi_dot([K, H, K.T])\n",
    "            w, V = scipy.linalg.eig(a, b)\n",
    "            ind = np.argsort(w)\n",
    "            A = V[:, ind[:self.dim]]\n",
    "            Z = np.dot(A.T, K)\n",
    "            Z /= np.linalg.norm(Z, axis=0)\n",
    "            Xs_new, Xt_new = Z[:, :ns].T, Z[:, ns:].T\n",
    "\n",
    "            clf = KNeighborsClassifier(n_neighbors=1)\n",
    "            clf.fit(Xs_new, Ys.ravel())\n",
    "            Y_tar_pseudo = clf.predict(Xt_new)\n",
    "            acc = sklearn.metrics.accuracy_score(Yt, Y_tar_pseudo)\n",
    "            list_acc.append(acc)\n",
    "            print('JDA iteration [{}/{}]: Acc: {:.4f}'.format(t + 1, self.T, acc))\n",
    "        return acc, Y_tar_pseudo, list_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDA iteration [1/5]: Acc: 0.6583\n",
      "JDA iteration [2/5]: Acc: 0.6656\n",
      "JDA iteration [3/5]: Acc: 0.6599\n",
      "JDA iteration [4/5]: Acc: 0.6596\n",
      "JDA iteration [5/5]: Acc: 0.6617\n",
      "A--> R: The accuracy of JCA is: 0.6617\n"
     ]
    }
   ],
   "source": [
    "jda_AR = JDA(kernel_type='primal', dim=30, lamb=1, gamma=1,T=5)\n",
    "acc_AR, ypre_AR, list_acc_AR = jda_AR.fit_predict(sd_features_AA,sd_labels_AA,td_features_AR,td_labels_AR)\n",
    "print(f'A--> R: The accuracy of JDA is: {acc_AR:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDA iteration [1/5]: Acc: 0.5869\n",
      "JDA iteration [2/5]: Acc: 0.6084\n",
      "JDA iteration [3/5]: Acc: 0.5922\n",
      "JDA iteration [4/5]: Acc: 0.5894\n",
      "JDA iteration [5/5]: Acc: 0.5912\n",
      "C--> R: The accuracy of JCA is: 0.5912\n"
     ]
    }
   ],
   "source": [
    "jda_CR = JDA(kernel_type='primal', dim=30, lamb=1, gamma=1,T=5)\n",
    "acc_CR, ypre_CR, list_acc_CR = jda_CR.fit_predict(sd_features_CC,sd_labels_CC,td_features_CR,td_labels_CR)\n",
    "print(f'C--> R: The accuracy of JDA is: {acc_CR:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDA iteration [1/5]: Acc: 0.6888\n",
      "JDA iteration [2/5]: Acc: 0.6989\n",
      "JDA iteration [3/5]: Acc: 0.6780\n",
      "JDA iteration [4/5]: Acc: 0.6780\n",
      "JDA iteration [5/5]: Acc: 0.6764\n",
      "P--> R: The accuracy of JCA is: 0.6764\n"
     ]
    }
   ],
   "source": [
    "jda_PR = JDA(kernel_type='primal', dim=30, lamb=1, gamma=1,T=5)\n",
    "acc_PR, ypre_PR, list_acc_PR = jda_PR.fit_predict(sd_features_PP,sd_labels_PP,td_features_PR,td_labels_PR)\n",
    "print(f'P--> R: The accuracy of JDA is: {acc_PR:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 3. BDA (Balanced Distribution Adaptation)\n",
    "**Main idea:**\n",
    "JDA同时适配边缘分布和条件分布，但是对于不同的任务，边缘分布和条件分布并不是同等重要，因此，BDA方法可以有效衡量（通过平衡因子）这两个分布的权重，从而达到最好的结果。BDA优化的目标为：$$D(D_S,D_T) \\approx (1-\\mu)||\\frac{1}{n}\\sum_{i=1}^n x_{s_i} - \\frac{1}{m}\\sum_{j=1}^m x_{t_j}||^2 + \\mu ||\\frac{1}{n_c}\\sum_{x_{s_i} \\in D_s^{(c)}}^n x_{s_i} - \\frac{1}{m_c}\\sum_{x_{t_j} \\in D_t^{(c)}}^n x_{t_j}||^2$$\n",
    "\n",
    "如何求解平衡因子$\\mu$？采用A-distance估计：\n",
    "- Calculate total A-distance of source domain and target domain.  -->A\n",
    "- Apply clustering in target domain, get the class $c_1,c_2,...c_k$. Calculate the cluster A-distance for each pair of class in source domain and target domain.  -->B\n",
    "- $\\mu=\\frac{A}{B},\\mu \\in [0,1]$. \n",
    "\n",
    "当$\\mu$ 趋近于0，表明源域和目标域之间不相似，因此优化边缘分布比较重要；当$\\mu$ 趋近于1，表明源域和目标域之间很相似，因此优化条件分布比较重要。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class BDA:\n",
    "    def __init__(self, kernel_type='primal', dim=30, lamb=1, mu=0.5, gamma=1, T=10, mode='BDA', estimate_mu=False):\n",
    "        '''\n",
    "        Init func\n",
    "        :param kernel_type: kernel, values: 'primal' | 'linear' | 'rbf'\n",
    "        :param dim: dimension after transfer\n",
    "        :param lamb: lambda value in equation\n",
    "        :param mu: mu. Default is -1, if not specificied, it calculates using A-distance\n",
    "        :param gamma: kernel bandwidth for rbf kernel\n",
    "        :param T: iteration number\n",
    "        :param mode: 'BDA' | 'WBDA'\n",
    "        :param estimate_mu: True | False, if you want to automatically estimate mu instead of manally set it\n",
    "        '''\n",
    "        self.kernel_type = kernel_type\n",
    "        self.dim = dim\n",
    "        self.lamb = lamb\n",
    "        self.mu = mu\n",
    "        self.gamma = gamma\n",
    "        self.T = T\n",
    "        self.mode = mode\n",
    "        self.estimate_mu = estimate_mu\n",
    "\n",
    "    def fit_predict(self, Xs, Ys, Xt, Yt):\n",
    "        '''\n",
    "        Transform and Predict using 1NN as JDA paper did\n",
    "        :param Xs: ns * n_feature, source feature\n",
    "        :param Ys: ns * 1, source label\n",
    "        :param Xt: nt * n_feature, target feature\n",
    "        :param Yt: nt * 1, target label\n",
    "        :return: acc, y_pred, list_acc\n",
    "        '''\n",
    "        list_acc = []\n",
    "        X = np.hstack((Xs.T, Xt.T))\n",
    "        X /= np.linalg.norm(X, axis=0)\n",
    "        m, n = X.shape\n",
    "        ns, nt = len(Xs), len(Xt)\n",
    "        e = np.vstack((1 / ns * np.ones((ns, 1)), -1 / nt * np.ones((nt, 1))))\n",
    "        C = len(np.unique(Ys))\n",
    "        H = np.eye(n) - 1 / n * np.ones((n, n))\n",
    "        mu = self.mu\n",
    "        M = 0\n",
    "        Y_tar_pseudo = None\n",
    "        Xs_new = None\n",
    "        for t in range(self.T):\n",
    "            N = 0\n",
    "            M0 = e * e.T * C\n",
    "            if Y_tar_pseudo is not None and len(Y_tar_pseudo) == nt:\n",
    "                for c in range(0, C):\n",
    "                    e = np.zeros((n, 1))\n",
    "                    Ns = len(Ys[np.where(Ys == c)])\n",
    "                    Nt = len(Y_tar_pseudo[np.where(Y_tar_pseudo == c)])\n",
    "\n",
    "                    if self.mode == 'WBDA':\n",
    "                        Ps = Ns / len(Ys)\n",
    "                        Pt = Nt / len(Y_tar_pseudo)\n",
    "                        alpha = Pt / Ps\n",
    "                        mu = 1\n",
    "                    else:\n",
    "                        alpha = 1\n",
    "\n",
    "                    tt = Ys == c\n",
    "                    e[np.where(tt == True)] = 1 / Ns\n",
    "                    yy = Y_tar_pseudo == c\n",
    "                    ind = np.where(yy == True)\n",
    "                    inds = [item + ns for item in ind]\n",
    "                    e[tuple(inds)] = -alpha / Nt\n",
    "                    e[np.isinf(e)] = 0\n",
    "                    N = N + np.dot(e, e.T)\n",
    "\n",
    "            # In BDA, mu can be set or automatically estimated using A-distance\n",
    "            # In WBDA, we find that setting mu=1 is enough\n",
    "            if self.estimate_mu and self.mode == 'BDA':\n",
    "                if Xs_new is not None:\n",
    "                    mu = estimate_mu(Xs_new, Ys, Xt_new, Y_tar_pseudo)\n",
    "                else:\n",
    "                    mu = 0\n",
    "            M = (1 - mu) * M0 + mu * N\n",
    "            M /= np.linalg.norm(M, 'fro')\n",
    "            K = kernel(self.kernel_type, X, None, gamma=self.gamma)\n",
    "            n_eye = m if self.kernel_type == 'primal' else n\n",
    "            a, b = np.linalg.multi_dot(\n",
    "                [K, M, K.T]) + self.lamb * np.eye(n_eye), np.linalg.multi_dot([K, H, K.T])\n",
    "            w, V = scipy.linalg.eig(a, b)\n",
    "            ind = np.argsort(w)\n",
    "            A = V[:, ind[:self.dim]]\n",
    "            Z = np.dot(A.T, K)\n",
    "            Z /= np.linalg.norm(Z, axis=0)\n",
    "            Xs_new, Xt_new = Z[:, :ns].T, Z[:, ns:].T\n",
    "\n",
    "            clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "            clf.fit(Xs_new, Ys.ravel())\n",
    "            Y_tar_pseudo = clf.predict(Xt_new)\n",
    "            acc = sklearn.metrics.accuracy_score(Yt, Y_tar_pseudo)\n",
    "            list_acc.append(acc)\n",
    "            print('{} iteration [{}/{}]: Acc: {:.4f}'.format(self.mode, t + 1, self.T, acc))\n",
    "        return acc, Y_tar_pseudo, list_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDA iteration [1/10]: Acc: 0.6583\n",
      "BDA iteration [2/10]: Acc: 0.6656\n",
      "BDA iteration [3/10]: Acc: 0.6599\n",
      "BDA iteration [4/10]: Acc: 0.6596\n",
      "BDA iteration [5/10]: Acc: 0.6617\n",
      "BDA iteration [6/10]: Acc: 0.6617\n",
      "BDA iteration [7/10]: Acc: 0.6608\n",
      "BDA iteration [8/10]: Acc: 0.6615\n",
      "BDA iteration [9/10]: Acc: 0.6610\n",
      "BDA iteration [10/10]: Acc: 0.6610\n",
      "A--> R: The accuracy of BDA is: 0.6610\n"
     ]
    }
   ],
   "source": [
    "bda_AR = BDA(kernel_type='primal', dim=30, lamb=1, mu=0.5, mode='BDA', gamma=1, estimate_mu=False,T=5)\n",
    "acc_AR, ypre_AR, list_acc_AR = bda_AR.fit_predict(sd_features_AA,sd_labels_AA,td_features_AR,td_labels_AR)\n",
    "print(f'A--> R: The accuracy of BDA is: {acc_AR:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDA iteration [1/5]: Acc: 0.5869\n",
      "BDA iteration [2/5]: Acc: 0.6084\n",
      "BDA iteration [3/5]: Acc: 0.5922\n",
      "BDA iteration [4/5]: Acc: 0.5894\n",
      "BDA iteration [5/5]: Acc: 0.5912\n",
      "C--> R: The accuracy of BDA is: 0.5912\n"
     ]
    }
   ],
   "source": [
    "bda_CR = BDA(kernel_type='primal', dim=30, lamb=1, mu=0.5, mode='BDA', gamma=1, estimate_mu=False,T=5)\n",
    "acc_CR, ypre_CR, list_acc_CR = bda_CR.fit_predict(sd_features_CC,sd_labels_CC,td_features_CR,td_labels_CR)\n",
    "print(f'C--> R: The accuracy of BDA is: {acc_CR:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BDA iteration [1/5]: Acc: 0.6888\n",
      "BDA iteration [2/5]: Acc: 0.6989\n",
      "BDA iteration [3/5]: Acc: 0.6780\n",
      "BDA iteration [4/5]: Acc: 0.6780\n",
      "BDA iteration [5/5]: Acc: 0.6764\n",
      "P--> R: The accuracy of BDA is: 0.6764\n"
     ]
    }
   ],
   "source": [
    "bda_PR = BDA(kernel_type='primal', dim=30, lamb=1, mu=0.5, mode='BDA', gamma=1, estimate_mu=False,T=5)\n",
    "acc_PR, ypre_PR, list_acc_PR = bda_PR.fit_predict(sd_features_PP,sd_labels_PP,td_features_PR,td_labels_PR)\n",
    "print(f'P--> R: The accuracy of BDA is: {acc_PR:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.1 WBDA (Weighted BDA)\n",
    "**Difference between WBDA and BDA:**\n",
    "Add weights for each of the class in target domain: $w_i=\\frac{c_{it}}{c_{is}}$, where $c_{1t},c_{2t},...c_{kt}$ are the number of class $i$ in target domain and $c_{1s},c_{2s},...c_{ks}$ are the number of class $i$ in source domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBDA iteration [1/5]: Acc: 0.6583\n",
      "WBDA iteration [2/5]: Acc: 0.6702\n",
      "WBDA iteration [3/5]: Acc: 0.6709\n",
      "WBDA iteration [4/5]: Acc: 0.6709\n",
      "WBDA iteration [5/5]: Acc: 0.6704\n",
      "A--> R: The accuracy of WBDA is: 0.6704\n"
     ]
    }
   ],
   "source": [
    "bda_AR = BDA(kernel_type='primal', dim=30, lamb=1, mode='WBDA', gamma=1, estimate_mu=False,T=5)\n",
    "acc_AR, ypre_AR, list_acc_AR = bda_AR.fit_predict(sd_features_AA,sd_labels_AA,td_features_AR,td_labels_AR)\n",
    "print(f'A--> R: The accuracy of WBDA is: {acc_AR:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBDA iteration [1/5]: Acc: 0.5869\n",
      "WBDA iteration [2/5]: Acc: 0.6103\n",
      "WBDA iteration [3/5]: Acc: 0.6149\n",
      "WBDA iteration [4/5]: Acc: 0.6117\n",
      "WBDA iteration [5/5]: Acc: 0.6140\n",
      "C--> R: The accuracy of BDA is: 0.6140\n"
     ]
    }
   ],
   "source": [
    "bda_CR = BDA(kernel_type='primal', dim=30, lamb=1, mode='WBDA', gamma=1, estimate_mu=False,T=5)\n",
    "acc_CR, ypre_CR, list_acc_CR = bda_CR.fit_predict(sd_features_CC,sd_labels_CC,td_features_CR,td_labels_CR)\n",
    "print(f'C--> R: The accuracy of WBDA is: {acc_CR:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WBDA iteration [1/5]: Acc: 0.6888\n",
      "WBDA iteration [2/5]: Acc: 0.6874\n",
      "WBDA iteration [3/5]: Acc: 0.6986\n",
      "WBDA iteration [4/5]: Acc: 0.6954\n",
      "WBDA iteration [5/5]: Acc: 0.6980\n",
      "P--> R: The accuracy of BDA is: 0.6980\n"
     ]
    }
   ],
   "source": [
    "bda_PR = BDA(kernel_type='primal', dim=30, lamb=1, mode='WBDA', gamma=1, estimate_mu=False,T=5)\n",
    "acc_PR, ypre_PR, list_acc_PR = bda_PR.fit_predict(sd_features_PP,sd_labels_PP,td_features_PR,td_labels_PR)\n",
    "print(f'P--> R: The accuracy of WBDA is: {acc_PR:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "从实验结果我们可以看到，BDA的效果要优于TCA和JDA，这从BDA的工作原理上可以得到较好的解释：\n",
    "- BDA is better than TCA because BDA's optimization goal considers the conditional distribution. Thus, when the source domain and target domain is similar, BDA can learn more cross-domain knowledge through the optimization of conditional distribution difference.\n",
    "- BDA is better than JDA because it introduce the self-adapatation mechemism: balance factor. For different tasks, edge distribution and condition distribution are not equally important. BDA method can effectively measure the weight of the two distributions (through the balance factor), so as to achieve the best results. Therefore, it's more general than JDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. CORAL (CORelation ALignment)\n",
    "**Main idea:**\n",
    "CORAL uses a linear transformation method to `align` (minimize the distance) the second-order statistical features of the source domain and target domain distribution. It is very effective for unsupervised domain adaptation.\n",
    "\n",
    "CORAL uses the Frobenius norm as the matrix distance metric. The optimization goal of CORAL is:\n",
    "$$\\min_A ||C_{S'} - C_T||_F^2 = \\min_A ||A^TC_SA - C_T||_F^2$$\n",
    "where:\n",
    "\n",
    "$A$ is the linear transformation matrix\n",
    "\n",
    "$C_{S'}$ is the covariance of the transformed source features $D_SA$ and $||\\cdot||_F^2$ \n",
    "\n",
    "$C_S$ and $C_T$ are the feature vector covariance matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CORAL:\n",
    "    def __init__(self):\n",
    "        super(CORAL, self).__init__()\n",
    "\n",
    "    def fit(self, Xs, Xt):\n",
    "        '''\n",
    "        Perform CORAL on the source domain features\n",
    "        :param Xs: ns * n_feature, source feature\n",
    "        :param Xt: nt * n_feature, target feature\n",
    "        :return: New source domain features\n",
    "        '''\n",
    "        cov_src = np.cov(Xs.T) + np.eye(Xs.shape[1])\n",
    "        cov_tar = np.cov(Xt.T) + np.eye(Xt.shape[1])\n",
    "        A_coral = np.dot(scipy.linalg.fractional_matrix_power(cov_src, -0.5),\n",
    "                         scipy.linalg.fractional_matrix_power(cov_tar, 0.5))\n",
    "        Xs_new = np.real(np.dot(Xs, A_coral))\n",
    "        return Xs_new\n",
    "\n",
    "    def fit_predict(self, Xs, Ys, Xt, Yt):\n",
    "        '''\n",
    "        Perform CORAL, then predict using 1NN classifier\n",
    "        :param Xs: ns * n_feature, source feature\n",
    "        :param Ys: ns * 1, source label\n",
    "        :param Xt: nt * n_feature, target feature\n",
    "        :param Yt: nt * 1, target label\n",
    "        :return: Accuracy and predicted labels of target domain\n",
    "        '''\n",
    "        Xs_new = self.fit(Xs, Xt)\n",
    "        clf = sklearn.neighbors.KNeighborsClassifier(n_neighbors=1)\n",
    "        clf.fit(Xs_new, Ys.ravel())\n",
    "        y_pred = clf.predict(Xt)\n",
    "        acc = sklearn.metrics.accuracy_score(Yt, y_pred)\n",
    "        return acc, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A--> R: The accuracy of CORAL is: 0.6479\n",
      "C--> R: The accuracy of CORAL is: 0.5837\n",
      "P--> R: The accuracy of CORAL is: 0.6851\n"
     ]
    }
   ],
   "source": [
    "coral_AR = CORAL()\n",
    "coral_CR = CORAL()\n",
    "coral_PR = CORAL()\n",
    "acc_AR, ypre_AR = coral_AR.fit_predict(sd_features_AA,sd_labels_AA,td_features_AR,td_labels_AR)\n",
    "print(f'A--> R: The accuracy of CORAL is: {acc_AR:.4f}')\n",
    "acc_CR, ypre_CR = coral_CR.fit_predict(sd_features_CC,sd_labels_CC,td_features_CR,td_labels_CR)\n",
    "print(f'C--> R: The accuracy of CORAL is: {acc_CR:.4f}')\n",
    "acc_PR, ypre_PR = coral_PR.fit_predict(sd_features_PP,sd_labels_PP,td_features_PR,td_labels_PR)\n",
    "print(f'P--> R: The accuracy of CORAL is: {acc_PR:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:**\n",
    "虽然CORAL的结果要略差于pure KNN，但是要优于TCA。CORAL最大的优势在于它训练速度非常快，因为CORAL只是进行了简单的矩阵运算，没有像TCA那样需要进行特征分解，也没有像JDA,BDA这样的迭代过程。综合计算成本和时间成本，我们认为CORAL在此任务上的表现优于TCA和JDA。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}