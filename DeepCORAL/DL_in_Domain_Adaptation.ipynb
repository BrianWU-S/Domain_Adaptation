{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep CORAL\n",
    "**Main idea:**\n",
    "Though CORAL is very simple and it works surprisingly well in some unsupervised domain adaptation cases, it has some drawbacks:\n",
    "- CORAL lies on linear transformation.\n",
    "- CORAL is not end-to-end training.  --> It needs to extract the feature from the source domain and target domain first to apply linear transformation. Then it trains a simple classifier (e.g. SVM,KNN) separately.\n",
    "\n",
    "So we design Deep CORAL as below:\n",
    "![image.png](images/2.png)\n",
    "\n",
    "source数据的输出与source label进行监督训练，得到分类的loss。而target数据的输出由于没有标注数据进行监督训练，因此要和source进行适应，计算CORAL loss。最终的目的是要将分类loss和CORAL loss共同优化到最小，即source的分类更精确，target的输出与source的分布更相似。因此损失函数由两部分组成：\n",
    "$$l = l_{CLASS} + \\sum_{i=1}^t \\lambda_i l_{CORAL}$$\n",
    "\n",
    "Why:\n",
    "- 单纯最小化分类loss会导致模型对源域过拟合，在目标域上性能很差\n",
    "- 单纯对CORAL loss优化会恶化特征。    -->网络会将source和target数据映射，如果映射到了同一个点，CORAL loss会变为0，这样的特征是不能构建强大的分类器的。\n",
    "\n",
    "**Cons of DeepCORAL:**\n",
    "1. 学习非线性的变换，比CORAL更强大\n",
    "2. 比DAN优化起来更容易\n",
    "3. 可以无缝集成到CNN结构中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torchvision import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root_path, domain, batch_size, phase):\n",
    "    transform_dict = {\n",
    "        'src': transforms.Compose(\n",
    "        [transforms.RandomResizedCrop(224),\n",
    "         transforms.RandomHorizontalFlip(),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "         ]),\n",
    "        'tar': transforms.Compose(\n",
    "        [transforms.Resize(224),\n",
    "         transforms.ToTensor(),\n",
    "         transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                              std=[0.229, 0.224, 0.225]),\n",
    "         ])}\n",
    "    data = datasets.ImageFolder(root=os.path.join(root_path, domain), transform=transform_dict[phase])\n",
    "    data_loader = torch.utils.data.DataLoader(data, batch_size=batch_size, shuffle=phase=='src', drop_last=phase=='tar', num_workers=4)\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
